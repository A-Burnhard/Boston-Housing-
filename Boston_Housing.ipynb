{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAmuGyc/fQjhjF9bIa79VL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A-Burnhard/Boston-Housing-/blob/main/Boston_Housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Hn_BGAjeIa8C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regression_data = pd.read_csv('housing.csv')\n",
        "regression_data.head()"
      ],
      "metadata": {
        "id": "8cWfach7J62Q",
        "outputId": "d9ed0be0-f0a2-45d3-cd88-ca71775bbd45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      RM  LSTAT  PTRATIO      MEDV\n",
              "0  6.575   4.98     15.3  504000.0\n",
              "1  6.421   9.14     17.8  453600.0\n",
              "2  7.185   4.03     17.8  728700.0\n",
              "3  6.998   2.94     18.7  701400.0\n",
              "4  7.147   5.33     18.7  760200.0"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-7062f543-8989-4d5a-a717-f59b8b3fa027\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RM</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>MEDV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.575</td>\n",
              "      <td>4.98</td>\n",
              "      <td>15.3</td>\n",
              "      <td>504000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.421</td>\n",
              "      <td>9.14</td>\n",
              "      <td>17.8</td>\n",
              "      <td>453600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.185</td>\n",
              "      <td>4.03</td>\n",
              "      <td>17.8</td>\n",
              "      <td>728700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.998</td>\n",
              "      <td>2.94</td>\n",
              "      <td>18.7</td>\n",
              "      <td>701400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.147</td>\n",
              "      <td>5.33</td>\n",
              "      <td>18.7</td>\n",
              "      <td>760200.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7062f543-8989-4d5a-a717-f59b8b3fa027')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-6a6e2230-f960-4183-8714-398627e97350\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a6e2230-f960-4183-8714-398627e97350')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-6a6e2230-f960-4183-8714-398627e97350 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7062f543-8989-4d5a-a717-f59b8b3fa027 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7062f543-8989-4d5a-a717-f59b8b3fa027');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-processing**"
      ],
      "metadata": {
        "id": "rvvCueQwQHQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify missing values\n",
        "missing_values = regression_data.isnull().sum()\n",
        "print(\"Missing values:\\n\", missing_values)"
      ],
      "metadata": {
        "id": "bCtb1CpFQMyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace missing values with mean or median if any\n",
        "regression_data.fillna(regression_data.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "unWQwJ5LQUsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Identifying Duplicates**"
      ],
      "metadata": {
        "id": "DgQlKtqcovhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify duplicate rows\n",
        "duplicates = regression_data.duplicated()\n",
        "print(\"Duplicates instances: \\n\",duplicates)"
      ],
      "metadata": {
        "id": "SYxI71MDQaMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Outlier detection**"
      ],
      "metadata": {
        "id": "3M3xBNuqozH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data = regression_data\n",
        "\n",
        "# Visualize the distribution of each feature using box plots\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=data)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Boxplot of Features')\n",
        "plt.show()\n",
        "\n",
        "# Identify outliers using statistical methods (e.g., Z-score or IQR)\n",
        "# Z-score method\n",
        "from scipy.stats import zscore\n",
        "\n",
        "data = regression_data\n",
        "z_scores = zscore(data)\n",
        "outlier_threshold = 3  # Adjust the threshold as per your preference\n",
        "outliers = (abs(z_scores) > outlier_threshold).any(axis=1)\n",
        "\n",
        "# IQR method\n",
        "Q1 = data.quantile(0.25)\n",
        "Q3 = data.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)\n",
        "\n",
        "# Count the number of outliers\n",
        "num_outliers = outliers.sum()\n",
        "print(f\"Number of outliers: {num_outliers}\")\n",
        "\n",
        "# Decide whether to remove outliers or transform them\n",
        "remove_outliers = False\n",
        "\n",
        "if remove_outliers:\n",
        "    # Remove outliers from the dataset\n",
        "    data = data[~outliers]\n",
        "    print(\"Outliers removed.\")\n",
        "else:\n",
        "    # Transform outliers to a specific value\n",
        "    outlier_value = 8  # Choose an appropriate value for transformation\n",
        "    data[outliers] = outlier_value\n",
        "    print(\"Outliers transformed.\")\n",
        "\n",
        "# Updated visualization after handling outliers\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=data)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Boxplot of Features (After Outlier Handling)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jDlJ7bUWo3UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining X and Y values**"
      ],
      "metadata": {
        "id": "tc9XzsVUpbaG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "umldgnH6pckB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Influencial datapoint detection using leverage and cooks distance**"
      ],
      "metadata": {
        "id": "V5-Y4Bsho_zG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the Boston Housing dataset\n",
        "df = regression_data\n",
        "# Separate the target variable (y) and the independent variables (X)\n",
        "X = df.drop('MEDV', axis=1)\n",
        "y = df['MEDV']\n",
        "\n",
        "# Add a constant column to X for the intercept term in the regression model\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the Ordinary Least Squares (OLS) regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the leverage of each data point\n",
        "leverage = model.get_influence().hat_matrix_diag\n",
        "\n",
        "# Get Cook's distance for each data point\n",
        "cooks_distance = model.get_influence().cooks_distance[0]\n",
        "\n",
        "# Combine leverage and Cook's distance into a DataFrame\n",
        "influential_data_points = pd.DataFrame({'Leverage': leverage, \"Cook's Distance\": cooks_distance}, index=df.index)\n",
        "\n",
        "# Print the data points with high leverage and Cook's distance\n",
        "threshold_leverage = 2 * (X.shape[1] / X.shape[0])  # Threshold for high leverage points\n",
        "threshold_cooks_distance = 4 / (X.shape[0] - X.shape[1] - 1)  # Threshold for influential points\n",
        "\n",
        "print(\"Data Points with High Leverage:\")\n",
        "print(influential_data_points[influential_data_points['Leverage'] > threshold_leverage])\n",
        "\n",
        "print(\"\\nData Points with High Cook's Distance:\")\n",
        "print(influential_data_points[influential_data_points[\"Cook's Distance\"] > threshold_cooks_distance])\n"
      ],
      "metadata": {
        "id": "2EhzLaHEpEzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normality of the set of features using shapiro**"
      ],
      "metadata": {
        "id": "V4tokeizpoeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Boston Housing dataset\n",
        "boston = regression_data\n",
        "\n",
        "# Extract feature variables (independent variables)\n",
        "X = boston.drop(columns=[\"MEDV\"])  # Remove the target variable 'MEDV'\n",
        "\n",
        "# Add a constant column for the intercept in the regression model\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Target variable (dependent variable)\n",
        "y = boston[\"MEDV\"]\n",
        "\n",
        "# Loop through each feature and perform linear regression\n",
        "for feature in X.columns:\n",
        "    model = sm.OLS(y, X[feature])\n",
        "    results = model.fit()\n",
        "\n",
        "    # Get the residuals (differences between predicted values and actual values)\n",
        "    residuals = results.resid\n",
        "\n",
        "    # Check normality of residuals using a histogram\n",
        "    plt.figure()\n",
        "    plt.hist(residuals, bins=20)\n",
        "    plt.xlabel(\"Residuals\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(f\"{feature} Residuals Histogram\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "93NTj2DAppzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Transformation**"
      ],
      "metadata": {
        "id": "qaK2s0-Ypu6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Step 1: Load the Boston Housing dataset\n",
        "data = pd.read_csv(\"housing.csv\")\n",
        "\n",
        "# Step 2: Split the data into features (X) and target variable (y)\n",
        "X = data.drop(\"MEDV\", axis=1)  # Drop the target variable \"medv\" from the features\n",
        "y = data[\"MEDV\"]  # Target variable\n",
        "\n",
        "# Step 3: Apply the logarithmic transformation to the target variable (y)\n",
        "y_log = np.log1p(y)  # Use numpy's log1p to apply the logarithmic transformation\n",
        "\n",
        "# Step 4: Split the transformed data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Perform regression analysis (Optional, just for demonstration)\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Predict the transformed target variable on the test set\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Optional: Calculate the mean squared error (MSE) to evaluate the regression model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "9xfQrbapp0PR",
        "outputId": "aa219395-67f3-47e1-b1b4-a3b0f321573a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.037636239795666326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Selection**"
      ],
      "metadata": {
        "id": "jDR0USwAp3fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Load the Boston Housing dataset\n",
        "data = pd.read_csv(\"housing.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(\"MEDV\", axis=1)\n",
        "y = df[\"MEDV\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Create Recursive Feature Elimination (RFE) object\n",
        "rfe = RFE(model, n_features_to_select=5)\n",
        "\n",
        "# Fit the RFE on the training data\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X_train.columns[rfe.support_]\n",
        "\n",
        "# Print the selected features\n",
        "print(\"Selected Features:\")\n",
        "print(selected_features)\n"
      ],
      "metadata": {
        "id": "vtFPJcyRp8Zf",
        "outputId": "18f36763-f62b-4e0c-9a01-6d2080c9f353",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features:\n",
            "Index(['RM', 'LSTAT', 'PTRATIO'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Oversampling techniques using the Synthetic Minority Over-sampling Technique (SMOTE) to balance the imbalanced dataset**"
      ],
      "metadata": {
        "id": "kAL3cCMIqA9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Create a SMOTE object\n",
        "smote = SMOTE()\n",
        "\n",
        "# Perform oversampling\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Print the balanced class distribution\n",
        "print(\"Class distribution after SMOTE:\")\n",
        "print(y_resampled.value_counts())"
      ],
      "metadata": {
        "id": "-g1_2-18qIrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Selecting Appropriate Learners for Training and Validation (Decision trees  and Gradient boosting)**"
      ],
      "metadata": {
        "id": "jjAzemxSqLrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, LeaveOneOut, train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the Boston Housing dataset\n",
        "data = pd.read_csv(\"housing.csv\")\n",
        "\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('MEDV', axis=1)\n",
        "y = df['MEDV']\n",
        "\n",
        "# Define learners\n",
        "decision_tree = DecisionTreeRegressor()\n",
        "xgboost_model = XGBRegressor()\n",
        "\n",
        "# K-fold cross-validation\n",
        "k_folds = 5\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "decision_tree_rmse_kfold = []\n",
        "xgboost_rmse_kfold = []\n",
        "\n",
        "for train_idx, test_idx in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Fit and predict using Decision Tree\n",
        "    decision_tree.fit(X_train, y_train)\n",
        "    y_pred_dt = decision_tree.predict(X_test)\n",
        "    decision_tree_rmse_kfold.append(np.sqrt(mean_squared_error(y_test, y_pred_dt)))\n",
        "\n",
        "    # Fit and predict using XGBoost\n",
        "    xgboost_model.fit(X_train, y_train)\n",
        "    y_pred_xgb = xgboost_model.predict(X_test)\n",
        "    xgboost_rmse_kfold.append(np.sqrt(mean_squared_error(y_test, y_pred_xgb)))\n",
        "\n",
        "# Leave-one-out cross-validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "decision_tree_rmse_loo = []\n",
        "xgboost_rmse_loo = []\n",
        "\n",
        "for train_idx, test_idx in loo.split(X):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Fit and predict using Decision Tree\n",
        "    decision_tree.fit(X_train, y_train)\n",
        "    y_pred_dt = decision_tree.predict(X_test)\n",
        "    decision_tree_rmse_loo.append(np.sqrt(mean_squared_error(y_test, y_pred_dt)))\n",
        "\n",
        "    # Fit and predict using XGBoost\n",
        "    xgboost_model.fit(X_train, y_train)\n",
        "    y_pred_xgb = xgboost_model.predict(X_test)\n",
        "    xgboost_rmse_loo.append(np.sqrt(mean_squared_error(y_test, y_pred_xgb)))\n",
        "\n",
        "# Percentage split\n",
        "test_size = 0.3\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "# Fit and predict using Decision Tree\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_dt = decision_tree.predict(X_test)\n",
        "decision_tree_rmse_percentage_split = np.sqrt(mean_squared_error(y_test, y_pred_dt))\n",
        "\n",
        "# Fit and predict using XGBoost\n",
        "xgboost_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgboost_model.predict(X_test)\n",
        "xgboost_rmse_percentage_split = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
        "\n",
        "# Print the results\n",
        "print(f\"Decision Tree RMSE (K-Fold Cross-Validation): {np.mean(decision_tree_rmse_kfold)}\")\n",
        "print(f\"XGBoost RMSE (K-Fold Cross-Validation): {np.mean(xgboost_rmse_kfold)}\")\n",
        "\n",
        "print(f\"Decision Tree RMSE (Leave-One-Out Cross-Validation): {np.mean(decision_tree_rmse_loo)}\")\n",
        "print(f\"XGBoost RMSE (Leave-One-Out Cross-Validation): {np.mean(xgboost_rmse_loo)}\")\n",
        "\n",
        "print(f\"Decision Tree RMSE (Percentage Split): {decision_tree_rmse_percentage_split}\")\n",
        "print(f\"XGBoost RMSE (Percentage Split): {xgboost_rmse_percentage_split}\")\n"
      ],
      "metadata": {
        "id": "sWdTemhQtN3j",
        "outputId": "b62e581b-b2ab-4159-b00b-5cb7ce1f1af9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree RMSE (K-Fold Cross-Validation): 90781.17763188317\n",
            "XGBoost RMSE (K-Fold Cross-Validation): 71291.75389221856\n",
            "Decision Tree RMSE (Leave-One-Out Cross-Validation): 71541.71779141104\n",
            "XGBoost RMSE (Leave-One-Out Cross-Validation): 55397.33371676892\n",
            "Decision Tree RMSE (Percentage Split): 79220.64124961372\n",
            "XGBoost RMSE (Percentage Split): 64646.38874224775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**calculate RMSE and R-squared**"
      ],
      "metadata": {
        "id": "_x2lRVAMt5bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Calculate evaluation metrics using K-fold cross-validation for Decision Tree\n",
        "decision_tree_mse_kfold = cross_val_score(decision_tree, X, y, scoring='neg_mean_squared_error', cv=kf)\n",
        "decision_tree_rmse_kfold = np.sqrt(-decision_tree_mse_kfold)\n",
        "decision_tree_mae_kfold = cross_val_score(decision_tree, X, y, scoring='neg_mean_absolute_error', cv=kf)\n",
        "decision_tree_r2_kfold = cross_val_score(decision_tree, X, y, scoring='r2', cv=kf)\n",
        "\n",
        "# Calculate evaluation metrics using K-fold cross-validation for XGBoost\n",
        "xgboost_mse_kfold = cross_val_score(xgboost_model, X, y, scoring='neg_mean_squared_error', cv=kf)\n",
        "xgboost_rmse_kfold = np.sqrt(-xgboost_mse_kfold)\n",
        "xgboost_mae_kfold = cross_val_score(xgboost_model, X, y, scoring='neg_mean_absolute_error', cv=kf)\n",
        "xgboost_r2_kfold = cross_val_score(xgboost_model, X, y, scoring='r2', cv=kf)\n",
        "\n",
        "# Print the results\n",
        "print(\"Decision Tree Metrics (K-Fold Cross-Validation):\")\n",
        "print(f\"RMSE: {np.mean(decision_tree_rmse_kfold)}\")\n",
        "print(f\"MAE: {np.mean(np.abs(decision_tree_mae_kfold))}\")\n",
        "print(f\"R-squared: {np.mean(decision_tree_r2_kfold)}\")\n",
        "\n",
        "print(\"\\nXGBoost Metrics (K-Fold Cross-Validation):\")\n",
        "print(f\"RMSE: {np.mean(xgboost_rmse_kfold)}\")\n",
        "print(f\"MAE: {np.mean(np.abs(xgboost_mae_kfold))}\")\n",
        "print(f\"R-squared: {np.mean(xgboost_r2_kfold)}\")\n"
      ],
      "metadata": {
        "id": "o1YF53NawVeo",
        "outputId": "ff68c9ad-27ea-4e1b-94e5-83645a0be1a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Metrics (K-Fold Cross-Validation):\n",
            "RMSE: 84876.90999166263\n",
            "MAE: 58323.62297496318\n",
            "R-squared: 0.7726063374116167\n",
            "\n",
            "XGBoost Metrics (K-Fold Cross-Validation):\n",
            "RMSE: 67005.19322196867\n",
            "MAE: 46736.76556880525\n",
            "R-squared: 0.8496840167479753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already trained your regression model on the training data\n",
        "# and have the hold-out data in X_holdout and y_holdout\n",
        "\n",
        "# Assuming you have already trained your model on the training data and have the hold-out data in X_holdout and y_holdout\n",
        "# Assuming you have also scaled your training data using the StandardScaler\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Transform the training and validation data\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Assuming you have trained your model on the scaled training data (e.g., using 'model.fit(X_train_scaled, y_train)')\n",
        "# Now, you want to make predictions on the hold-out data (X_holdout)\n",
        "\n",
        "# Preprocess the hold-out data using the same scaler used for training data\n",
        "X_holdout_scaled = scaler.transform(X_holdout)\n",
        "\n",
        "# Make predictions on the hold-out data\n",
        "y_pred = model.predict(X_holdout_scaled)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_holdout, y_pred)\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Actual vs. Predicted Values (Regression)\")\n",
        "plt.show()\n",
        "\n",
        "# Create a residual plot\n",
        "residuals = y_holdout - y_pred\n",
        "plt.scatter(y_holdout, residuals)\n",
        "plt.axhline(y=0, color='r', linestyle='--')  # Add a reference line at y=0\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot (Regression)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Oa6dK2NEFQb6",
        "outputId": "222e5827-0ac4-4e17-8378-155a39603024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ea30dbbf5da6>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Preprocess the hold-out data using the same scaler used for training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mX_holdout_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_holdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Make predictions on the hold-out data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_holdout' is not defined"
          ]
        }
      ]
    }
  ]
}